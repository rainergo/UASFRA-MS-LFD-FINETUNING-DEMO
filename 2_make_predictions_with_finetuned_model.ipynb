{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## II. PREDICTION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 1. Import packages\n",
    "`pip install transformers torch datasets pandas`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel, pipeline\n",
    "import torch\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "\n",
    "# settings.py\n",
    "from settings import dataset_name, model_name, finetuned_model_name, finetuned_models_folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. Load dataset \"emotion\" - use test subset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(dataset_name)\n",
    "labels = pd.Series(list(dataset.data['test'].columns[2])).unique().astype(str).tolist()\n",
    "print('Labels of \"emotion\" test dataset:', labels)\n",
    "print(f'Size of \"emotion\" test datset: {len(dataset.data[\"test\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\"\"\"  Example: \"\"\"')\n",
    "index = 42\n",
    "print(f\"TEXT: '{dataset['test']['text'][index]}'\")\n",
    "print(f\"LABEL: {dataset['test']['label'][index]}\")\n",
    "print(f\"LABEL_TEXT: {dataset['test']['label_text'][index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Load finetuned model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=f'./{finetuned_models_folder}/{finetuned_model_name}',local_files_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4. Tokenize text (test subset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize random sample sentences from test set\n",
    "num_samples = 100\n",
    "sample_index = random.sample(range(len(dataset.data[\"test\"])), num_samples)\n",
    "samples_text = [dataset['test']['text'][x] for x in sample_index]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokens = tokenizer(samples_text, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 5. Make predictions for test subset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: DO NOT TRAIN FOR PREDICTION - FREEZE MODEL - NO BACKPROPAGATION:\n",
    "with torch.no_grad():\n",
    "    # Make prediction:\n",
    "    model_output = finetuned_model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION Values and Labels\n",
    "pred_labels = torch.argmax(model_output.logits, axis=-1).numpy().tolist()\n",
    "pred_labels_text = [labels[x] for x in pred_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL Values and Labels\n",
    "labels = [dataset['test']['label'][x] for x in sample_index]\n",
    "labels_text = [dataset['test']['label_text'][x] for x in sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put everything into a pandas DataFrame\n",
    "df = pd.DataFrame(data={'text': samples_text, 'real_labels': labels,'real_labels_text': labels_text,'pred_labels':pred_labels, 'pred_labels_text':pred_labels_text})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 6. Show correct/good and incorrect/bad predictions in a DataFrame\n",
    "###### (Please note that this might change for every run of this notebook depending on the randomly chosen samples above)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good predictions\n",
    "df_good_preds = df.query('real_labels == pred_labels')\n",
    "print(f'Number of correct/good predictions: {len(df_good_preds.index)}')\n",
    "df_good_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad predictions\n",
    "df_bad_preds = df.query('real_labels != pred_labels')\n",
    "print(f'Number of incorrect/bad predictions: {len(df_bad_preds.index)}')\n",
    "df_bad_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Percentage of correctly predicted sample labels: {float(len(df_good_preds.index)*100/(len(df_bad_preds.index) + len(df_good_preds.index)))} %')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
